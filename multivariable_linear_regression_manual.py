# -*- coding: utf-8 -*-
"""multivariable_linear_regression_manual.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YQuoX8CmQh_6O61ww3PlodXmHRmUzmQB
"""

import numpy as np
import pandas as pd
import time

# content = "crop_yield(Indian data_set).csv"
content = "crop_yield(USA data_set).csv"
path = "data_set"
path_content = f"{path}/{content}"

df = pd.read_csv(path_content)
df_encoded = df.copy()
print(df)

# **USA data set encoding**

# # Mean encoding
crop_mean_yield = df_encoded.groupby('Crop')['Yield'].mean()
df_encoded['Crop'] = df_encoded['Crop'].map(crop_mean_yield)

# One-hot encoding
# df_encoded = pd.get_dummies(df, columns=['Crop'])

# **Indian data set encoding**

# # # Mean encoding
# crop_mean_yield = df_encoded.groupby('Crop')['Yield'].mean()
# season_mean_yield = df_encoded.groupby('Season')['Yield'].mean()
# state_mean_yield = df_encoded.groupby('State')['Yield'].mean()
# df_encoded['Crop'] = df_encoded['Crop'].map(crop_mean_yield)
# df_encoded['Season'] = df_encoded['Season'].map(season_mean_yield)
# df_encoded['State'] = df_encoded['State'].map(state_mean_yield)

# # One-hot encoding
# # df_encoded = pd.get_dummies(df, columns=['Crop', 'Season', 'State'])

# **Data set display**

print(df_encoded)

# **Check for null value**

df_encoded.isnull().sum()

# **Independent variables**

X = df_encoded.drop(columns=['Yield'])
print(X)

# **Dependent variable**

y = df_encoded['Yield']
print(y)

# **Log transformation**

# y = np.log1p(y)

# **Calculate mean and standard deviation for each feature**

means = X.mean()
stds = X.std()

# **Apply standardization**

X_scaled = (X - means) / stds
X = np.c_[np.ones(X_scaled.shape[0]), X_scaled.values]

# **Gradient decent functions for lenear regression**

# Gradient Descent Parameters
m, n = X.shape  # Number of samples (m) and features (n)
coeff = np.zeros(n)
alpha = 0.01
iterations = 800
cost_history = []
start_time = time.time()
# Gradient Descent Function
for i in range(iterations):
    predictions = X.dot(coeff)  # Compute predictions
    errors = predictions - y  # Compute error
    gradient = (1 / m) * X.T.dot(errors)
    coeff -= alpha * gradient  # Update coeff using gradient descent

    # Compute and record cost (Mean Squared Error)
    cost = (1 / (2 * m)) * np.sum(errors ** 2)
    cost_history.append(cost)
end_time = time.time()
training_time = end_time - start_time
print("Training time:", training_time, "seconds")
print(coeff)

# **Multivariable linear regression**

# coeff = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)
# coeff

# **Predict the values of Y using the learned theta**

y_pred = X.dot(coeff)
print(y_pred)

mse = np.mean((y_pred - y) ** 2)
rmse = np.sqrt(mse)
print(rmse)

y_intercept = coeff[0]
print(y_intercept)

ss_total = np.sum((y - np.mean(y)) ** 2)
ss_residual = np.sum((y - y_pred) ** 2)
r_squared = 1 - (ss_residual / ss_total)
print(r_squared)

# **Important stuff**


print(f"Y-intercept (coefficient):\n\ttheta 0 --> {y_intercept} constant_value")
print("\nTheta (coefficients) for Features (independent variable):")

feature_names = df_encoded.drop(columns=['Yield']).columns
count = 1
for coefficient, feature in zip(coeff[1:], feature_names):
    print(f"\ttheta {count} --> {round(coefficient, 10)} for {feature}")
    count += 1
print(f"\nRoot Mean Squared Error (RMSE):\n\t{rmse}")
print(f"\nModel accuracy in training:\n\t{r_squared} or {round((r_squared*100), 2)}%")
print(f"\nTraining time:\n\t{round(training_time, 16)}ms")

feature_names = df_encoded.drop(columns=['Yield']).columns

abs_coefficients = np.abs(coeff[1:])
total_contribution = np.sum(abs_coefficients)
percentage_contributions = (abs_coefficients / total_contribution) * 100

feature_contributions = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': coeff[1:],
    'Contribution (%)': percentage_contributions
})

print(feature_contributions, "\n")
print("Total contribution", total_contribution)

import matplotlib.pyplot as plt

plt.figure(figsize=(16, 8))
bars = plt.bar(["y-Intercept"] + list(feature_names), coeff, color='skyblue', edgecolor='black')
plt.axhline(0, color='red', linestyle='--', linewidth=1)

for bar, value in zip(bars, coeff):
    height = bar.get_height()
    y_offset = 0.1 if height >= 0 else -0.1
    plt.text(bar.get_x() + bar.get_width() / 2, height + y_offset, f"{value:.4f}",
             ha='center', va='bottom' if height >= 0 else 'top', fontsize=10, color='black')

plt.title("Coefficients of Features and y-Intercept", fontsize=16)
plt.xlabel("Features", fontsize=14)
plt.ylabel("Coefficient Value", fontsize=14)
plt.xticks(rotation=45, ha="right", fontsize=12)
plt.tight_layout()
plt.show()

plt.figure(figsize=(16, 8))
bars = plt.barh(feature_contributions['Feature'], feature_contributions['Contribution (%)'], color='skyblue')
plt.suptitle('Spiked graph')
plt.title('Feature contribution')
plt.xlabel('Contribution (%)')
plt.gca().invert_yaxis()

for bar, percentage in zip(bars, percentage_contributions):
    plt.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height() / 2,
             f'{percentage:.2f}%', va='center')
plt.show()

plt.figure(figsize=(16, 8))
plt.plot(range(iterations), cost_history, label='Cost over iterations', color='blue')
plt.title('Cost Function Convergence')
plt.xlabel('Iterations')
plt.ylabel('Cost (MSE)')
plt.legend()
plt.show()

plt.figure(figsize=(16, 8))
plt.scatter(y, y_pred, color="skyblue", label="Predicted vs Actual")
plt.plot([y.min(), y.max()], [y.min(), y.max()], color="red", linestyle="--", label="y = x (Perfect Prediction)")
plt.grid(True, linestyle="--", alpha=0.7)
plt.title('Test Set: Actual vs Predicted Yield')
plt.xlabel('Actual Yield')
plt.ylabel('Predicted Yield')
plt.legend()
plt.suptitle('Actual vs Predicted Yield Comparison')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

plt.figure(figsize=(16, 8))
plt.plot(y.values, label='Original Yield Values', marker='o')
plt.plot(y_pred, label='Predicted Yield Values', marker='x')
plt.title('Comparison of Original and Predicted Yield Values')
plt.xlabel('Samples')
plt.ylabel('Yield')
plt.legend()
plt.show()

print("Actual vs Predicted Yield Values:")
for actual, predicted in zip(y, y_pred):
    print(f"Actual: {actual:.2f}, Predicted: {predicted:.2f}")